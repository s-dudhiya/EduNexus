{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-21T11:48:45.700131Z",
     "iopub.status.busy": "2025-08-21T11:48:45.699940Z",
     "iopub.status.idle": "2025-08-21T11:48:50.894710Z",
     "shell.execute_reply": "2025-08-21T11:48:50.893639Z",
     "shell.execute_reply.started": "2025-08-21T11:48:45.700113Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyngrok\n",
      "  Downloading pyngrok-7.3.0-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.13)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.46.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.11.7)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n",
      "Downloading pyngrok-7.3.0-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: pyngrok\n",
      "Successfully installed pyngrok-7.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pyngrok fastapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "execution_failed": "2025-08-21T12:26:40.319Z",
     "iopub.execute_input": "2025-08-21T11:49:06.451353Z",
     "iopub.status.busy": "2025-08-21T11:49:06.450701Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                    \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [36]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public URL: https://9dcf5203a971.ngrok-free.app\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib    #face point detect\n",
    "import numpy as np\n",
    "import json    \n",
    "from datetime import datetime\n",
    "import os\n",
    "import math\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import nest_asyncio\n",
    "from pyngrok import ngrok\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "\n",
    "\n",
    "HEAD_POSE_THRESHOLD = {\n",
    "    \"PITCH_DOWN\": 60,\n",
    "    \"YAW_SIDEWAYS\": 70,\n",
    "}\n",
    "\n",
    "YOLO_CONFIDENCE_THRESHOLD = 0.5 \n",
    "YOLO_NMS_THRESHOLD = 0.4  # IoU threshold for NMS\n",
    "YOLO_NMS_CONF_THRESHOLD = 0.3  # Minimum confidence for NMS\n",
    "\n",
    "\n",
    "FORBIDDEN_OBJECTS = [\"cell phone\", \"book\"]\n",
    "\n",
    "SHAPE_PREDICTOR_PATH = \"/kaggle/input/dataset-test/shape_predictor_68_face_landmarks.dat\"\n",
    "YOLO_CFG_PATH = \"/kaggle/input/dataset-test/yolov3.cfg\"\n",
    "YOLO_WEIGHTS_PATH = \"/kaggle/input/dataset-test/yolov3.weights\"\n",
    "COCO_NAMES_PATH = \"/kaggle/input/dataset-test/coco.names\"\n",
    "\n",
    "class SingleImageProctor:\n",
    " \n",
    "    def __init__(self):\n",
    "        # --- Model Initialization ---\n",
    "        self.predictor = None\n",
    "        self.net = None\n",
    "        self.classes = None\n",
    "        self.output_layers = None\n",
    "\n",
    "        # Load dlib models\n",
    "        if not os.path.exists(SHAPE_PREDICTOR_PATH):\n",
    "            raise FileNotFoundError(f\"Shape predictor file not found at {SHAPE_PREDICTOR_PATH}\")\n",
    "        self.detector = dlib.get_frontal_face_detector()\n",
    "        self.predictor = dlib.shape_predictor(SHAPE_PREDICTOR_PATH)\n",
    "\n",
    "        # Load YOLO models\n",
    "        if not os.path.exists(YOLO_WEIGHTS_PATH):\n",
    "            raise FileNotFoundError(f\"YOLO weights file not found at {YOLO_WEIGHTS_PATH}\")\n",
    "        if not os.path.exists(YOLO_CFG_PATH):\n",
    "            raise FileNotFoundError(f\"YOLO config file not found at {YOLO_CFG_PATH}\")\n",
    "        if not os.path.exists(COCO_NAMES_PATH):\n",
    "            raise FileNotFoundError(f\"COCO names file not found at {COCO_NAMES_PATH}\")\n",
    "\n",
    "        self.net = cv2.dnn.readNet(YOLO_WEIGHTS_PATH, YOLO_CFG_PATH)\n",
    "        self.layer_names = self.net.getLayerNames()\n",
    "        unconnected = self.net.getUnconnectedOutLayers()\n",
    "        if isinstance(unconnected, np.ndarray) and unconnected.ndim > 1:\n",
    "            unconnected = unconnected.flatten()\n",
    "        self.output_layers = [self.layer_names[i - 1] for i in unconnected]\n",
    "\n",
    "        with open(COCO_NAMES_PATH, \"r\") as f:\n",
    "            self.classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    def _get_head_pose(self, shape, frame_dims):\n",
    "      \n",
    "        model_points = np.array([\n",
    "            (0.0, 0.0, 0.0), \n",
    "            (0.0, -330.0, -65.0),\n",
    "            (-225.0, 170.0, -135.0),  \n",
    "            (225.0, 170.0, -135.0), \n",
    "            (-150.0, -150.0, -125.0),   \n",
    "            (150.0, -150.0, -125.0) \n",
    "        ], dtype=\"double\")\n",
    "\n",
    "        image_points = np.array([\n",
    "            (shape.part(30).x, shape.part(30).y),\n",
    "            (shape.part(8).x, shape.part(8).y),\n",
    "            (shape.part(36).x, shape.part(36).y),\n",
    "            (shape.part(45).x, shape.part(45).y),\n",
    "            (shape.part(48).x, shape.part(48).y),\n",
    "            (shape.part(54).x, shape.part(54).y)\n",
    "        ], dtype=\"double\")\n",
    "\n",
    "        focal_length = frame_dims[1]\n",
    "        center = (frame_dims[1] / 2, frame_dims[0] / 2)\n",
    "        camera_matrix = np.array(\n",
    "            [[focal_length, 0, center[0]],\n",
    "             [0, focal_length, center[1]],\n",
    "             [0, 0, 1]], dtype=\"double\"\n",
    "        )\n",
    "        dist_coeffs = np.zeros((4, 1))\n",
    "\n",
    "        success, rotation_vector, translation_vector, inliers = cv2.solvePnPRansac(\n",
    "            model_points, image_points, camera_matrix, dist_coeffs\n",
    "        )\n",
    "\n",
    "        if not success:\n",
    "            return 0.0, 0.0\n",
    "\n",
    "        theta = cv2.norm(rotation_vector, cv2.NORM_L2)\n",
    "        if theta == 0:\n",
    "            return 0.0, 0.0\n",
    "\n",
    "        w = math.cos(theta / 2)\n",
    "        x = math.sin(theta / 2) * rotation_vector[0][0] / theta\n",
    "        y = math.sin(theta / 2) * rotation_vector[1][0] / theta\n",
    "        z = math.sin(theta / 2) * rotation_vector[2][0] / theta\n",
    "\n",
    "        ysqr = y * y\n",
    "        t0 = 2.0 * (w * x + y * z)\n",
    "        t1 = 1.0 - 2.0 * (x * x + ysqr)\n",
    "        pitch = math.atan2(t0, t1)\n",
    "\n",
    "        t2 = 2.0 * (w * y - z * x)\n",
    "        t2 = max(min(t2, 1.0), -1.0)\n",
    "        yaw = math.asin(t2)\n",
    "\n",
    "        pitch_deg = (pitch / math.pi) * 180\n",
    "        yaw_deg = (yaw / math.pi) * 180\n",
    "\n",
    "        return pitch_deg, yaw_deg\n",
    "\n",
    "    def _detect_forbidden_objects(self, frame):\n",
    "   \n",
    "        if self.net is None or self.classes is None or self.output_layers is None:\n",
    "            raise ValueError(\"YOLO models not loaded.\")\n",
    "\n",
    "        height, width, _ = frame.shape\n",
    "        blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "        self.net.setInput(blob)\n",
    "        outs = self.net.forward(self.output_layers)\n",
    "\n",
    "        class_ids = []\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > YOLO_CONFIDENCE_THRESHOLD and self.classes[class_id] in FORBIDDEN_OBJECTS:\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "\n",
    "        indices = cv2.dnn.NMSBoxes(boxes, confidences, YOLO_NMS_CONF_THRESHOLD, YOLO_NMS_THRESHOLD)\n",
    "\n",
    "        detected_objects = []\n",
    "        if len(indices) > 0:\n",
    "            for i in indices.flatten():\n",
    "                detected_objects.append({\n",
    "                    \"type\": \"Object Detected\",\n",
    "                    \"details\": f\"Forbidden object detected: {self.classes[class_ids[i]]}\",\n",
    "                    \"confidence\": confidences[i],\n",
    "                    \"box\": boxes[i]\n",
    "                })\n",
    "        return detected_objects\n",
    "\n",
    "    def analyze_image(self, frame):\n",
    "    \n",
    "        events = []\n",
    "        frame_dims = frame.shape\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = self.detector(gray)\n",
    "\n",
    "        num_faces = len(faces)\n",
    "        if num_faces > 1:\n",
    "            events.append({\"type\": \"Multiple People\", \"details\": f\"{num_faces} faces detected.\", \"confidence\": 1.0})\n",
    "        elif num_faces == 0:\n",
    "            events.append({\"type\": \"Person Absent\", \"details\": \"No person detected in the image.\", \"confidence\": 1.0})\n",
    "        else:\n",
    "            face = faces[0]\n",
    "            shape = self.predictor(gray, face)\n",
    "            pitch, yaw = self._get_head_pose(shape, frame_dims)\n",
    "            if pitch > HEAD_POSE_THRESHOLD[\"PITCH_DOWN\"]:\n",
    "                excess = (pitch - HEAD_POSE_THRESHOLD[\"PITCH_DOWN\"]) / (90 - HEAD_POSE_THRESHOLD[\"PITCH_DOWN\"])\n",
    "                conf = min(0.5 + 0.5 * excess, 1.0)\n",
    "                events.append({\"type\": \"Looking Down\", \"details\": f\"Head pitch at {pitch:.2f}°, exceeds threshold of {HEAD_POSE_THRESHOLD['PITCH_DOWN']}°.\", \"confidence\": conf})\n",
    "            if abs(yaw) > HEAD_POSE_THRESHOLD[\"YAW_SIDEWAYS\"]:\n",
    "                direction = \"right\" if yaw > 0 else \"left\"\n",
    "                excess = (abs(yaw) - HEAD_POSE_THRESHOLD[\"YAW_SIDEWAYS\"]) / (90 - HEAD_POSE_THRESHOLD[\"YAW_SIDEWAYS\"])\n",
    "                conf = min(0.5 + 0.5 * excess, 1.0)\n",
    "                events.append({\"type\": \"Looking Sideways\", \"details\": f\"Head yawed {abs(yaw):.2f}° {direction}, exceeds threshold of {HEAD_POSE_THRESHOLD['YAW_SIDEWAYS']}°.\", \"confidence\": conf})\n",
    "\n",
    "        try:\n",
    "            object_events = self._detect_forbidden_objects(frame)\n",
    "            events.extend(object_events)\n",
    "        except ValueError as e:\n",
    "            events.append({\"type\": \"Model Error\", \"details\": str(e), \"confidence\": 1.0})\n",
    "\n",
    "        face_box = [faces[0].left(), faces[0].top(), faces[0].width(), faces[0].height()] if num_faces == 1 else None\n",
    "        return {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"cheating_detected\": any(e[\"confidence\"] > 0.7 for e in events),\n",
    "            \"events\": events,\n",
    "            \"face_box\": face_box\n",
    "        }\n",
    "\n",
    "try:\n",
    "    proctor = SingleImageProctor()\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing proctor: {e}\")\n",
    "    raise\n",
    "\n",
    "app = FastAPI()\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"], \n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"], \n",
    "    allow_headers=[\"*\"], \n",
    ")\n",
    "\n",
    "class ImageRequest(BaseModel):\n",
    "    image_base64: str\n",
    "\n",
    "def decode_base64_image(base64_str: str):\n",
    "    if base64_str.startswith(\"data:\"):\n",
    "        base64_str = base64_str.split(\",\", 1)[1]\n",
    "\n",
    "    missing_padding = len(base64_str) % 4\n",
    "    if missing_padding:\n",
    "        base64_str += \"=\" * (4 - missing_padding)\n",
    "\n",
    "    image_data = base64.b64decode(base64_str)\n",
    "    nparr = np.frombuffer(image_data, np.uint8)\n",
    "    image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "    return image\n",
    "\n",
    "@app.post(\"/analyze\")\n",
    "async def analyze_image_endpoint(request: ImageRequest):\n",
    "    try:\n",
    "        image = decode_base64_image(request.image_base64)\n",
    "        if image is None:\n",
    "            raise ValueError(\"Could not decode the image from base64. Ensure it's a valid base64-encoded image without errors.\")\n",
    "\n",
    "        result = proctor.analyze_image(image)\n",
    "        return result\n",
    "    except base64.binascii.Error as e:\n",
    "        raise HTTPException(status_code=400, detail=f\"Invalid base64 encoding: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    nest_asyncio.apply()\n",
    "    ngrok.set_auth_token('2s9bOqSkXKz3lX3oI41LOP5MWTi_4oJFcA4gSTB5ugts3rSY9')\n",
    "    ngrok_tunnel = ngrok.connect(8000)\n",
    "    print('Public URL:', ngrok_tunnel.public_url)\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8099491,
     "sourceId": 12809175,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
